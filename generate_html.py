import requests
import os

AIPIPE_TOKEN = os.environ.get("AIPIPE_TOKEN")
AIPIPE_URL = "https://aipipe.org/openrouter/v1/chat/completions"
MODEL = "qwen/qwen3-coder:free"  # change to other "free" models if needed

def get_code_from_llm(brief, checks, attachments):
    prompt = f"""You are an expert web developer. Generate a beautiful, professional, responsive HTML5 and JS app using Tailwind CSS for the following task.

Requirements:
- Use [Tailwind CSS via CDN](https://cdn.jsdelivr.net/npm/tailwindcss@2.2.19/dist/tailwind.min.css) for all styling‚Äîmake the UI modern and visually appealing.
- Use Google Fonts for headings if possible.
- Make it fully responsive and mobile-friendly.
- Add meaningful page structure (centered layout, spacing, shadows, cards, headers, etc).
- All buttons/inputs should be clear, large enough, and easy to interact with.
- Include placeholder icons if visually helpful.

Brief:
{brief}

Checks:
{checks}

Attachments (descriptions only, do not depend on file contents unless sample given):
{attachments}

VERY IMPORTANT:
- Output only a complete, ready-to-serve index.html file with all code (JS in <script> tag, Tailwind via CDN, etc).
- Your result should be visually impressive, feel professional, and have clear separation of concerns in UI.
- No explanation, only code.
- Top-align all content, proper background, padding, rounded, and readable font sizing.
"""
    headers = {
        "Authorization": f"Bearer {AIPIPE_TOKEN}",
        "Content-Type": "application/json",
    }
    payload = {
        "model": MODEL,
        "messages": [
            {"role": "system", "content": "You are a helpful AI code generator."},
            {"role": "user", "content": prompt}
        ],
        "temperature": 0.2,
        "max_tokens": 1400
    }

    try:
        resp = requests.post(AIPIPE_URL, headers=headers, json=payload, timeout=60)
        result = resp.json()
        if "choices" in result and len(result["choices"]) > 0:
            return result['choices'][0]['message']['content']
        elif "error" in result:
            err = result["error"]
            msg = err["message"] if isinstance(err, dict) and "message" in err else str(err)
            return f"<h2 style='color:red;'>LLM API ERROR: {msg}</h2>"
        else:
            return f"<h2 style='color:red;'>Unexpected LLM API response:<br>{result}</h2>"
    except Exception as e:
        return f"<h2 style='color:red;'>Server exception: {e}</h2>"

def generate_task_html(task_json, output_dir="."):
    code = get_code_from_llm(
        task_json.get("brief"),
        task_json.get("checks"),
        task_json.get("attachments", [])
    )
    with open(os.path.join(output_dir, "index.html"), "w", encoding="utf-8") as f:
        f.write(code)

def generate_task_readme(task_json, output_dir="."):
    task = task_json.get('task', 'Task')
    round_num = task_json.get('round', '')
    brief = task_json.get('brief', '')
    evaluation_url = task_json.get('evaluation_url', '')
    attachments = task_json.get('attachments', [])
    checks = task_json.get('checks', [])

    readme_content = f"""# LLM Code Deployment

[![Deploy Status](https://img.shields.io/badge/deploy-on--render-brightgreen)](https://project-llm-code-deployment.onrender.com/api-endpoint)

## üöÄ Project Overview

This repo is an **auto-generated single-page web app** for a specific LLM-assisted TDS Project 1 task.

- **Current Task:** `{task}`
- **Round:** `{round_num}`
- **App Brief:**  
  > {brief}

---

## üìã Features (This Task)

- LLM-generated, ready-to-use web app for the current task brief
- Deploys to [GitHub Pages](https://ajmalmiitm.github.io/Project-LLM-Code-Deployment/)
- Receives its brief/updates by secure API POST

---

## ‚ö° Task Metadata

| Field         | Value                        |
|---------------|-----------------------------|
| Task          | `{task}`                    |
| Round         | `{round_num}`               |
| Evaluation URL| `{evaluation_url}`          |
| Attachments   | {", ".join(f"`{att['name']}`" for att in attachments) if attachments else "‚Äî"} |

### ‚úÖ Auto-Evaluation Checks

{chr(10).join(f'- [ ] {chk}' for chk in checks) if checks else "_No checks provided_"}

---

## üìú API Info

- API endpoint for future POSTs:  
  [`https://project-llm-code-deployment.onrender.com/api-endpoint`](https://project-llm-code-deployment.onrender.com/api-endpoint)

- This deployment is managed fully by automated LLM code generation.

---

## üìù License

MIT License [(LICENSE)](LICENSE)

---

_Made with ‚ù§Ô∏è for IITM TDS Project 1 ‚Äî auto-generated by LLM Code Deployment system._
"""
    with open(os.path.join(output_dir, "README.md"), "w", encoding="utf-8") as f:
        f.write(readme_content)
